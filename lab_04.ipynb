{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab-04.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXCuC8MLAMmkYtHUyDwy8m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmy0792/pytorch_tutorial/blob/main/lab_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multivariate Linear Regression"
      ],
      "metadata": {
        "id": "lCq1MBL37ccE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim"
      ],
      "metadata": {
        "id": "oryGx0dH7g8b"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train=torch.FloatTensor([[73,80,75],\n",
        "                           [93,88,93],\n",
        "                           [89,91,90],\n",
        "                           [96,98,100],\n",
        "                           [73,66,70]])\n",
        "y_train=torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
        "\n",
        "# 모델 초기화\n",
        "W=torch.zeros((3,1),requires_grad=True)\n",
        "b=torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD([W,b],lr=1e-5)\n"
      ],
      "metadata": {
        "id": "DBmNeaP97x4r"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=20\n",
        "for epoch in range(nb_epochs +1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train.matmul(W) + b\n",
        "\n",
        "  # cost 계산 (MSE)\n",
        "  cost=torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step() #updates parameter\n",
        "\n",
        "  print('Epoch {:4d}/{}  hypothesis: {} Cost: {:.6f}'.format(\n",
        "      epoch,nb_epochs, hypothesis.squeeze().detach(), # detach: 기존 Tensor에서 gradient 전파가 안되는 텐서 생성\n",
        "      cost.item()\n",
        "  ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKKZ7Tht8Ec4",
        "outputId": "b5d37a38-69db-46bd-ac2a-660e86705b99"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20  hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\n",
            "Epoch    1/20  hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712402\n",
            "Epoch    2/20  hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040527\n",
            "Epoch    3/20  hypothesis: tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936096\n",
            "Epoch    4/20  hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371063\n",
            "Epoch    5/20  hypothesis: tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]) Cost: 29.758249\n",
            "Epoch    6/20  hypothesis: tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]) Cost: 10.445267\n",
            "Epoch    7/20  hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391237\n",
            "Epoch    8/20  hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493121\n",
            "Epoch    9/20  hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\n",
            "Epoch   10/20  hypothesis: tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]) Cost: 1.710552\n",
            "Epoch   11/20  hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651416\n",
            "Epoch   12/20  hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632369\n",
            "Epoch   13/20  hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625924\n",
            "Epoch   14/20  hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623420\n",
            "Epoch   15/20  hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622152\n",
            "Epoch   16/20  hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621262\n",
            "Epoch   17/20  hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]) Cost: 1.620501\n",
            "Epoch   18/20  hypothesis: tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]) Cost: 1.619757\n",
            "Epoch   19/20  hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]) Cost: 1.619046\n",
            "Epoch   20/20  hypothesis: tensor([152.8022, 183.6741, 180.9683, 197.0706, 140.1009]) Cost: 1.618348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## nn.Module을 사용하여 모델 생성"
      ],
      "metadata": {
        "id": "_d9h6n6l_8GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "S4w6CkNBAA15"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear=nn.Linear(3,1)\n",
        "\n",
        "  def forward(self,x): # hypothesis 계산\n",
        "    return self.linear(x)\n",
        "\n",
        "hypothesis=model(x_train)"
      ],
      "metadata": {
        "id": "V5XgRCpzADkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.nn.functional의 loss function 사용"
      ],
      "metadata": {
        "id": "4T_bZLx5BAPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# 쉽게 다른 loss와 교체 가능\n",
        "#cost = F.mse_loss(prediction,y_train)"
      ],
      "metadata": {
        "id": "jvMtzz0UBDKj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터\n",
        "x_train=torch.FloatTensor([[73,80,75],\n",
        "                           [93,88,93],\n",
        "                           [89,91,90],\n",
        "                           [96,98,100],\n",
        "                           [73,66,70]])\n",
        "y_train=torch.FloatTensor([[152],[185],[180],[196],[142]])\n",
        "\n",
        "# 모델 초기화\n",
        "model=MultivariateLinearRegressionModel()\n",
        "\n",
        "# optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(),lr=1e-5)\n",
        "\n",
        "\n",
        "# 학습\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  hypothesis = model(x_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost = F.mse_loss(hypothesis,y_train)\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch {:4d}/{}  hypothesis: {} Cost: {:.6f}'.format(\n",
        "      epoch,nb_epochs, hypothesis.squeeze().detach(), # detach: 기존 Tensor에서 gradient 전파가 안되는 텐서 생성\n",
        "      cost.item()\n",
        "  ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYsn3LptAUdI",
        "outputId": "94300968-d9a4-4014-c679-b3359c0bf14d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20  hypothesis: tensor([42.1518, 51.6074, 50.4483, 54.3867, 39.9636]) Cost: 15421.927734\n",
            "Epoch    1/20  hypothesis: tensor([ 90.6490, 109.8979, 107.8827, 116.9313,  84.4246]) Cost: 4834.392578\n",
            "Epoch    2/20  hypothesis: tensor([117.8007, 142.5327, 140.0380, 151.9477, 109.3169]) Cost: 1515.763550\n",
            "Epoch    3/20  hypothesis: tensor([133.0018, 160.8037, 158.0406, 171.5521, 123.2532]) Cost: 475.549805\n",
            "Epoch    4/20  hypothesis: tensor([141.5123, 171.0332, 168.1196, 182.5278, 131.0558]) Cost: 149.497040\n",
            "Epoch    5/20  hypothesis: tensor([146.2768, 176.7603, 173.7623, 188.6727, 135.4242]) Cost: 47.297050\n",
            "Epoch    6/20  hypothesis: tensor([148.9442, 179.9668, 176.9215, 192.1130, 137.8701]) Cost: 15.262662\n",
            "Epoch    7/20  hypothesis: tensor([150.4375, 181.7620, 178.6902, 194.0390, 139.2395]) Cost: 5.221419\n",
            "Epoch    8/20  hypothesis: tensor([151.2734, 182.7672, 179.6803, 195.1174, 140.0063]) Cost: 2.073836\n",
            "Epoch    9/20  hypothesis: tensor([151.7413, 183.3301, 180.2347, 195.7210, 140.4357]) Cost: 1.087108\n",
            "Epoch   10/20  hypothesis: tensor([152.0031, 183.6453, 180.5450, 196.0589, 140.6762]) Cost: 0.777640\n",
            "Epoch   11/20  hypothesis: tensor([152.1496, 183.8218, 180.7187, 196.2481, 140.8110]) Cost: 0.680461\n",
            "Epoch   12/20  hypothesis: tensor([152.2315, 183.9207, 180.8159, 196.3540, 140.8866]) Cost: 0.649848\n",
            "Epoch   13/20  hypothesis: tensor([152.2772, 183.9762, 180.8703, 196.4133, 140.9289]) Cost: 0.640090\n",
            "Epoch   14/20  hypothesis: tensor([152.3027, 184.0073, 180.9007, 196.4464, 140.9528]) Cost: 0.636860\n",
            "Epoch   15/20  hypothesis: tensor([152.3169, 184.0248, 180.9177, 196.4650, 140.9662]) Cost: 0.635686\n",
            "Epoch   16/20  hypothesis: tensor([152.3247, 184.0347, 180.9272, 196.4753, 140.9739]) Cost: 0.635156\n",
            "Epoch   17/20  hypothesis: tensor([152.3290, 184.0403, 180.9325, 196.4811, 140.9783]) Cost: 0.634828\n",
            "Epoch   18/20  hypothesis: tensor([152.3313, 184.0435, 180.9354, 196.4843, 140.9808]) Cost: 0.634561\n",
            "Epoch   19/20  hypothesis: tensor([152.3324, 184.0454, 180.9370, 196.4860, 140.9824]) Cost: 0.634316\n",
            "Epoch   20/20  hypothesis: tensor([152.3330, 184.0465, 180.9379, 196.4870, 140.9833]) Cost: 0.634087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Dataset, DataLoader"
      ],
      "metadata": {
        "id": "XtSXTIdXEpoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "ofL7wKzTEtkK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data=[[73,80,75],\n",
        "                 [93,88,93],\n",
        "                 [89,91,90],\n",
        "                 [96,98,100],\n",
        "                 [73,66,70]]\n",
        "    self.y_data=[[152],[185],[180],[196],[142]]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    x=torch.FloatTensor(self.x_data[idx])\n",
        "    y=torch.FloatTensor(self.y_data[idx])\n",
        "    return x,y\n",
        "\n",
        "dataset=CustomDataset()"
      ],
      "metadata": {
        "id": "j5afNvWJEvzs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "nu_F-IqbFf_V"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=2, # 각 minibatch의 크기\n",
        "    shuffle=True, # epoch마다 데이터셋 섞어서 데이터가 학습되는 순서를 바꾼다\n",
        ")"
      ],
      "metadata": {
        "id": "iLwuadSOFjd3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=MultivariateLinearRegressionModel()\n",
        "optimizer = optim.SGD(model.parameters(),lr=1e-5)\n",
        "\n",
        "\n",
        "nb_epochs=20\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train,y_train=samples\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction=model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{}  Batch: {}/{} Cost: {:.6f}'.format(\n",
        "      epoch,nb_epochs, batch_idx+1, len(dataloader), # detach: 기존 Tensor에서 gradient 전파가 안되는 텐서 생성\n",
        "      cost.item()\n",
        "  ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaS7oLCPFzye",
        "outputId": "fe78909d-7ad4-4edd-c682-69be3aed2b2c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/20  Batch: 1/3 Cost: 21048.320312\n",
            "Epoch    0/20  Batch: 2/3 Cost: 16734.615234\n",
            "Epoch    0/20  Batch: 3/3 Cost: 3035.065674\n",
            "Epoch    1/20  Batch: 1/3 Cost: 653.142944\n",
            "Epoch    1/20  Batch: 2/3 Cost: 393.204010\n",
            "Epoch    1/20  Batch: 3/3 Cost: 43.578411\n",
            "Epoch    2/20  Batch: 1/3 Cost: 26.893318\n",
            "Epoch    2/20  Batch: 2/3 Cost: 9.918231\n",
            "Epoch    2/20  Batch: 3/3 Cost: 1.189956\n",
            "Epoch    3/20  Batch: 1/3 Cost: 1.946731\n",
            "Epoch    3/20  Batch: 2/3 Cost: 0.142445\n",
            "Epoch    3/20  Batch: 3/3 Cost: 1.457182\n",
            "Epoch    4/20  Batch: 1/3 Cost: 0.167780\n",
            "Epoch    4/20  Batch: 2/3 Cost: 0.697871\n",
            "Epoch    4/20  Batch: 3/3 Cost: 0.950191\n",
            "Epoch    5/20  Batch: 1/3 Cost: 0.847172\n",
            "Epoch    5/20  Batch: 2/3 Cost: 0.298989\n",
            "Epoch    5/20  Batch: 3/3 Cost: 0.122932\n",
            "Epoch    6/20  Batch: 1/3 Cost: 0.797054\n",
            "Epoch    6/20  Batch: 2/3 Cost: 0.034976\n",
            "Epoch    6/20  Batch: 3/3 Cost: 0.482039\n",
            "Epoch    7/20  Batch: 1/3 Cost: 0.180369\n",
            "Epoch    7/20  Batch: 2/3 Cost: 0.343475\n",
            "Epoch    7/20  Batch: 3/3 Cost: 1.896000\n",
            "Epoch    8/20  Batch: 1/3 Cost: 0.251069\n",
            "Epoch    8/20  Batch: 2/3 Cost: 0.759495\n",
            "Epoch    8/20  Batch: 3/3 Cost: 0.504695\n",
            "Epoch    9/20  Batch: 1/3 Cost: 0.177912\n",
            "Epoch    9/20  Batch: 2/3 Cost: 1.222407\n",
            "Epoch    9/20  Batch: 3/3 Cost: 0.040048\n",
            "Epoch   10/20  Batch: 1/3 Cost: 0.376319\n",
            "Epoch   10/20  Batch: 2/3 Cost: 0.641712\n",
            "Epoch   10/20  Batch: 3/3 Cost: 0.670287\n",
            "Epoch   11/20  Batch: 1/3 Cost: 0.132338\n",
            "Epoch   11/20  Batch: 2/3 Cost: 0.886636\n",
            "Epoch   11/20  Batch: 3/3 Cost: 0.076472\n",
            "Epoch   12/20  Batch: 1/3 Cost: 0.644149\n",
            "Epoch   12/20  Batch: 2/3 Cost: 0.016581\n",
            "Epoch   12/20  Batch: 3/3 Cost: 0.867016\n",
            "Epoch   13/20  Batch: 1/3 Cost: 0.210617\n",
            "Epoch   13/20  Batch: 2/3 Cost: 0.717254\n",
            "Epoch   13/20  Batch: 3/3 Cost: 0.644652\n",
            "Epoch   14/20  Batch: 1/3 Cost: 0.096367\n",
            "Epoch   14/20  Batch: 2/3 Cost: 1.327530\n",
            "Epoch   14/20  Batch: 3/3 Cost: 0.058080\n",
            "Epoch   15/20  Batch: 1/3 Cost: 0.230660\n",
            "Epoch   15/20  Batch: 2/3 Cost: 0.279822\n",
            "Epoch   15/20  Batch: 3/3 Cost: 1.388568\n",
            "Epoch   16/20  Batch: 1/3 Cost: 0.678989\n",
            "Epoch   16/20  Batch: 2/3 Cost: 0.544369\n",
            "Epoch   16/20  Batch: 3/3 Cost: 0.050203\n",
            "Epoch   17/20  Batch: 1/3 Cost: 0.417819\n",
            "Epoch   17/20  Batch: 2/3 Cost: 1.067668\n",
            "Epoch   17/20  Batch: 3/3 Cost: 0.127598\n",
            "Epoch   18/20  Batch: 1/3 Cost: 0.563999\n",
            "Epoch   18/20  Batch: 2/3 Cost: 0.534257\n",
            "Epoch   18/20  Batch: 3/3 Cost: 0.333171\n",
            "Epoch   19/20  Batch: 1/3 Cost: 0.944721\n",
            "Epoch   19/20  Batch: 2/3 Cost: 0.148603\n",
            "Epoch   19/20  Batch: 3/3 Cost: 0.128712\n",
            "Epoch   20/20  Batch: 1/3 Cost: 0.058047\n",
            "Epoch   20/20  Batch: 2/3 Cost: 0.638135\n",
            "Epoch   20/20  Batch: 3/3 Cost: 0.789955\n"
          ]
        }
      ]
    }
  ]
}